import requests
import re
import os
import time
import ipaddress
import json
import logging
from concurrent.futures import ThreadPoolExecutor, as_completed
import threading
from queue import Queue
from datetime import datetime
from functools import wraps

# ========== é…ç½® ==========
CONFIG = {
    'urls': [
        'https://ip.164746.xyz', 
        'https://api.uouin.com/cloudflare.html',
        'https://ipdb.api.030101.xyz/?type=bestcf&country=true',
        'https://addressesapi.090227.xyz/CloudFlareYes',
        'https://raw.githubusercontent.com/ymyuuu/IPDB/main/BestCF/bestcfv4.txt',
        'https://www.wetest.vip/page/cloudflare/address_v6.html',
        'https://www.wetest.vip/page/cloudflare/address_v4.html',
        'https://raw.githubusercontent.com/crow1874/CF-DNS-Clone/refs/heads/main/030101-bestcf.txt',
        'https://raw.githubusercontent.com/crow1874/CF-DNS-Clone/refs/heads/main/wetest-cloudflare-v4.txt',
        'https://raw.githubusercontent.com/ZhiXuanWang/cf-speed-dns/refs/heads/main/ipTop10.html',
        'https://raw.githubusercontent.com/gslege/CloudflareIP/refs/heads/main/result.txt',
        'https://raw.githubusercontent.com/camel52zhang/yxip/refs/heads/main/ip.txt',
        'https://raw.githubusercontent.com/Senflare/Senflare-IP/refs/heads/main/IPlist.txt',
        'https://raw.githubusercontent.com/hubbylei/bestcf/refs/heads/main/bestcf.txt'
    ],
    'request_timeout': 15,
    'max_workers_url': 8,
    'max_workers_ip_query': 12,
    'max_retries': 3,
    'results_folder': 'cf_ip_results',
    'baidu_api_timeout': 10,
    'batch_size': 500,
}

# IPåœ°å€æ­£åˆ™è¡¨è¾¾å¼
ipv4_pattern = r'\b(25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\.(25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\.(25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\.(25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\b'
ipv6_pattern = r'(?:[A-Fa-f0-9]{1,4}:){7}[A-Fa-f0-9]{1,4}|(?:[A-Fa-f0-9]{1,4}:){1,7}:|(?:[A-Fa-f0-9]{1,4}:){1,6}:[A-Fa-f0-9]{1,4}'

# è¯·æ±‚å¤´
headers = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
    'Accept': 'text/html,application/json,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
    'Accept-Language': 'en-US,en;q=0.5',
    'Accept-Encoding': 'gzip, deflate, br',
    'Connection': 'keep-alive',
}

# Cloudflare IPèŒƒå›´
CF_IP_RANGES = {
    'ipv4': [
        '173.245.48.0/20', '103.21.244.0/22', '103.22.200.0/22', '103.31.4.0/22',
        '141.101.64.0/18', '108.162.192.0/18', '190.93.240.0/20', '188.114.96.0/20',
        '197.234.240.0/22', '198.41.128.0/17', '162.158.0.0/15', '104.16.0.0/13',
        '104.24.0.0/14', '172.64.0.0/13', '131.0.72.0/22'
    ],
    'ipv6': [
        '2606:4700::/32', '2803:f800::/32', '2405:b500::/32', '2405:8100::/32',
        '2a06:98c0::/29', '2c0f:f248::/32'
    ]
}

# å…¨å±€å˜é‡
progress_lock = threading.Lock()
completed_count = 0
total_count = 0
success_count = 0

# ========== æ—¥å¿—è®¾ç½® ==========
def setup_logging():
    """è®¾ç½®æ—¥å¿—è®°å½•"""
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s',
        handlers=[
            logging.StreamHandler()
        ]
    )

# ========== å·¥å…·å‡½æ•° ==========
def timer(func):
    """è®¡æ—¶è£…é¥°å™¨"""
    @wraps(func)
    def wrapper(*args, **kwargs):
        start_time = time.time()
        result = func(*args, **kwargs)
        end_time = time.time()
        logging.info(f'{func.__name__} æ‰§è¡Œæ—¶é—´: {end_time - start_time:.2f}ç§’')
        return result
    return wrapper

def fetch_url_with_retry(url, max_retries=3):
    """å¸¦é‡è¯•æœºåˆ¶çš„URLè·å–"""
    for attempt in range(max_retries):
        try:
            response = requests.get(url, headers=headers, timeout=CONFIG['request_timeout'])
            response.raise_for_status()
            return response.text
        except requests.exceptions.RequestException as e:
            if attempt == max_retries - 1:
                logging.warning(f'è¯·æ±‚ {url} å¤±è´¥ (å°è¯• {attempt + 1} æ¬¡): {e}')
                return None
            logging.info(f'è¯·æ±‚ {url} å¤±è´¥ï¼Œç¬¬ {attempt + 1} æ¬¡é‡è¯•...')
            time.sleep(2)  # é‡è¯•å‰ç­‰å¾…

def validate_cloudflare_ip(ip, is_ipv6=False):
    """éªŒè¯æ˜¯å¦ä¸ºCloudflare IPèŒƒå›´"""
    try:
        if is_ipv6:
            ip_obj = ipaddress.IPv6Address(ip)
            cf_ranges = [ipaddress.IPv6Network(net) for net in CF_IP_RANGES['ipv6']]
        else:
            ip_obj = ipaddress.IPv4Address(ip)
            cf_ranges = [ipaddress.IPv4Network(net) for net in CF_IP_RANGES['ipv4']]
        
        return any(ip_obj in network for network in cf_ranges)
    except Exception as e:
        logging.debug(f'IPéªŒè¯å¤±è´¥ {ip}: {e}')
        return False

def extract_ips_from_text(text):
    """ä»æ–‡æœ¬ä¸­æå–IPåœ°å€"""
    ipv4_matches = re.findall(ipv4_pattern, text)
    ipv6_matches = re.findall(ipv6_pattern, text)
    
    valid_ipv4 = set()
    valid_ipv6 = set()
    
    # éªŒè¯IPv4åœ°å€
    for ip in ipv4_matches:
        try:
            if isinstance(ip, tuple):
                ip_str = '.'.join(ip)
            else:
                ip_str = ip
            
            if validate_cloudflare_ip(ip_str, False):
                ipaddress.IPv4Address(ip_str)
                valid_ipv4.add(ip_str)
        except (ValueError, ipaddress.AddressValueError):
            continue
    
    # éªŒè¯IPv6åœ°å€
    for ip in ipv6_matches:
        try:
            ip_obj = ipaddress.IPv6Address(ip)
            if validate_cloudflare_ip(ip, True):
                valid_ipv6.add(ip_obj.compressed.lower())
        except (ValueError, ipaddress.AddressValueError):
            continue
    
    return valid_ipv4, valid_ipv6

def get_location_from_baidu(ip):
    """ä»ç™¾åº¦APIè·å–IPçš„åœ°ç†ä½ç½®ä¿¡æ¯"""
    try:
        url = f'https://opendata.baidu.com/api.php?co=&resource_id=6006&oe=utf8&query={ip}&lang=en'
        resp = requests.get(url, headers=headers, timeout=CONFIG['baidu_api_timeout'])
        
        if resp.status_code == 200:
            try:
                data = resp.json()
                status = data.get('status')
                if status == '0':
                    if data.get('data') and len(data['data']) > 0:
                        location = data['data'][0].get('location', 'æœªçŸ¥')
                        if location and location != 'æœªçŸ¥':
                            return location, True
            except json.JSONDecodeError:
                pass
    except Exception as e:
        logging.debug(f'ç™¾åº¦APIæŸ¥è¯¢å¤±è´¥ {ip}: {e}')
    
    return 'æœªçŸ¥', False

def process_single_ip(ip):
    """å¤„ç†å•ä¸ªIPåœ°å€æŸ¥è¯¢"""
    global completed_count, success_count
    
    location, success = get_location_from_baidu(ip)
    
    with progress_lock:
        completed_count += 1
        if success:
            success_count += 1
        
        # æ¯å¤„ç†50ä¸ªIPæˆ–å®Œæˆæ—¶æ˜¾ç¤ºè¿›åº¦
        if completed_count % 50 == 0 or completed_count == total_count:
            success_rate = (success_count / completed_count * 100) if completed_count > 0 else 0
            logging.info(f'è¿›åº¦: {completed_count}/{total_count} (æˆåŠŸç‡: {success_rate:.1f}%)')
    
    return ip, location, success

@timer
def process_urls_parallel(urls, max_workers=None):
    """å¹¶è¡Œå¤„ç†URLè·å–"""
    if max_workers is None:
        max_workers = CONFIG['max_workers_url']
    
    all_ipv4 = set()
    all_ipv6 = set()
    failed_urls = []
    
    with ThreadPoolExecutor(max_workers=max_workers) as executor:
        future_to_url = {executor.submit(fetch_url_with_retry, url): url for url in urls}
        
        for future in as_completed(future_to_url):
            url = future_to_url[future]
            try:
                text = future.result()
                if text:
                    ipv4, ipv6 = extract_ips_from_text(text)
                    all_ipv4.update(ipv4)
                    all_ipv6.update(ipv6)
                    logging.info(f'âœ… æˆåŠŸå¤„ç†: {url} (IPv4: {len(ipv4)}, IPv6: {len(ipv6)})')
                else:
                    failed_urls.append(url)
            except Exception as e:
                logging.error(f'âŒ å¤„ç† {url} æ—¶å‡ºé”™: {e}')
                failed_urls.append(url)
    
    if failed_urls:
        logging.warning(f'å¤±è´¥çš„æ•°æ®æº: {len(failed_urls)} ä¸ª')
    
    return all_ipv4, all_ipv6

@timer
def query_ips_parallel(ip_set, max_workers=None, is_ipv6=False):
    """å¹¶è¡ŒæŸ¥è¯¢IPåœ°å€çš„åœ°ç†ä½ç½®"""
    global completed_count, total_count, success_count
    
    if max_workers is None:
        max_workers = CONFIG['max_workers_ip_query']
    
    # é‡ç½®è®¡æ•°å™¨
    completed_count = 0
    total_count = len(ip_set)
    success_count = 0
    
    if not ip_set:
        return []
    
    ip_type = "IPv6" if is_ipv6 else "IPv4"
    logging.info(f'å¼€å§‹å¹¶è¡ŒæŸ¥è¯¢ {total_count} ä¸ª{ip_type}åœ°å€çš„åœ°ç†ä½ç½®...')
    logging.info(f'ä½¿ç”¨ {max_workers} ä¸ªçº¿ç¨‹åŒæ—¶æŸ¥è¯¢')
    
    results = []
    ip_list = list(ip_set)
    
    # åˆ†æ‰¹å¤„ç†ä»¥é¿å…å†…å­˜é—®é¢˜
    for i in range(0, len(ip_list), CONFIG['batch_size']):
        batch = ip_list[i:i + CONFIG['batch_size']]
        logging.info(f'å¤„ç†æ‰¹æ¬¡ {i//CONFIG["batch_size"] + 1}/{(len(ip_list)-1)//CONFIG["batch_size"] + 1}')
        
        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            future_to_ip = {executor.submit(process_single_ip, ip): ip for ip in batch}
            
            for future in as_completed(future_to_ip):
                try:
                    ip, location, success = future.result()
                    results.append((ip, location))
                except Exception as e:
                    ip = future_to_ip[future]
                    logging.error(f"å¤„ç†IP {ip} æ—¶å‘ç”Ÿå¼‚å¸¸: {e}")
                    results.append((ip, 'æœªçŸ¥'))
        
        # æ‰¹æ¬¡é—´ä¼‘æ¯
        if i + CONFIG['batch_size'] < len(ip_list):
            time.sleep(1)
    
    # æœ€ç»ˆè¿›åº¦æ˜¾ç¤º
    success_rate = (success_count / total_count * 100) if total_count > 0 else 0
    logging.info(f'âœ… æŸ¥è¯¢å®Œæˆ: æ€»è®¡ {total_count}, æˆåŠŸ {success_count}, æˆåŠŸç‡: {success_rate:.1f}%')
    
    return results

def is_us_location(location):
    """åˆ¤æ–­æ˜¯å¦ä¸ºç¾å›½åŒºåŸŸ"""
    us_keywords = ['ç¾å›½', 'United States', 'US', 'USA', 'åŠ åˆ©ç¦å°¼äºš', 'åŠ å·', 'æ´›æ‰çŸ¶', 
                   'æ—§é‡‘å±±', 'çº½çº¦', 'èŠåŠ å“¥', 'è¥¿é›…å›¾', 'è¾¾æ‹‰æ–¯', 'äºšç‰¹å…°å¤§', 'è¿ˆé˜¿å¯†', 'åç››é¡¿']
    
    if not location or location == 'æœªçŸ¥':
        return False
    
    location_lower = location.lower()
    return any(keyword.lower() in location_lower for keyword in us_keywords)

def save_results_with_location(ip_results, filename, is_ipv6=False):
    """ä¿å­˜ç»“æœåˆ°æ–‡ä»¶ï¼Œå¹¶åˆ†ç¦»ç¾å›½å’Œéç¾å›½IP"""
    if not ip_results:
        logging.warning(f'æ²¡æœ‰è¦ä¿å­˜çš„{"IPv6" if is_ipv6 else "IPv4"}åœ°å€ç»“æœã€‚')
        return [], []
    
    # æŒ‰IPåœ°å€æ’åºç»“æœ
    if is_ipv6:
        sorted_results = sorted(ip_results, key=lambda x: x[0])
    else:
        sorted_results = sorted(ip_results, key=lambda x: [int(part) for part in x[0].split('.')])
    
    # åˆ†ç¦»ç¾å›½å’Œéç¾å›½IP
    us_results = []
    non_us_results = []
    failed_count = 0
    
    for ip, location in sorted_results:
        if location == 'æœªçŸ¥':
            failed_count += 1
        
        if is_us_location(location):
            us_results.append((ip, location))
        else:
            non_us_results.append((ip, location))
    
    # ä¿å­˜æ‰€æœ‰IPåˆ°æ–‡ä»¶
    all_results = []
    for ip, location in sorted_results:
        if is_ipv6:
            all_results.append(f"[{ip}]:8443#{location}-IPV6")
        else:
            all_results.append(f"{ip}:8443#{location}")
    
    with open(filename, 'w', encoding='utf-8') as file:
        for line in all_results:
            file.write(line + '\n')
    
    ip_type = "IPv6" if is_ipv6 else "IPv4"
    logging.info(f'âœ… å·²ä¿å­˜ {len(all_results)} ä¸ª{ip_type}åœ°å€åˆ° {filename}')
    logging.info(f'ğŸ“Š æˆåŠŸè·å–åœ°ç†ä½ç½®: {len(all_results) - failed_count}, å¤±è´¥: {failed_count}')
    logging.info(f'ğŸŒ ç¾å›½IP: {len(us_results)}ä¸ª, éç¾å›½IP: {len(non_us_results)}ä¸ª')
    
    return non_us_results, us_results

def save_non_us_ips(non_us_ipv4, non_us_ipv6):
    """ä¿å­˜éç¾å›½IPåˆ°æ—¥æœŸæ—¶é—´å‘½åçš„æ–‡ä»¶ä¸­"""
    if not non_us_ipv4 and not non_us_ipv6:
        logging.info("æ²¡æœ‰éç¾å›½IPéœ€è¦ä¿å­˜ã€‚")
        return
    
    # åˆ›å»ºç»“æœæ–‡ä»¶å¤¹
    if not os.path.exists(CONFIG['results_folder']):
        os.makedirs(CONFIG['results_folder'])
    
    # ç”Ÿæˆæ—¥æœŸæ—¶é—´æ–‡ä»¶å
    current_time = datetime.now().strftime("%Y%m%d_%H%M%S")
    filename = f"non_us_ips_{current_time}.txt"
    filepath = os.path.join(CONFIG['results_folder'], filename)
    
    # åˆå¹¶IPv4å’ŒIPv6ç»“æœ
    all_results = []
    
    # å¤„ç†IPv4
    for ip, location in non_us_ipv4:
        all_results.append(f"{ip}:8443#{location}")
    
    # å¤„ç†IPv6
    for ip, location in non_us_ipv6:
        all_results.append(f"[{ip}]:8443#{location}-IPV6")
    
    # ä¿å­˜åˆ°æ–‡ä»¶
    with open(filepath, 'w', encoding='utf-8') as file:
        for line in all_results:
            file.write(line + '\n')
    
    logging.info(f'âœ… å·²ä¿å­˜ {len(all_results)} ä¸ªéç¾å›½IPåˆ° {filepath}')
    logging.info(f'ğŸ“Š å…¶ä¸­IPv4: {len(non_us_ipv4)}ä¸ª, IPv6: {len(non_us_ipv6)}ä¸ª')

def clean_old_files():
    """æ¸…ç†æ—§æ–‡ä»¶ï¼Œä½†ä¿ç•™ç»“æœæ–‡ä»¶å¤¹"""
    for filename in ['ip.txt', 'ipv6.txt']:
        if os.path.exists(filename):
            os.remove(filename)
            logging.info(f'å·²åˆ é™¤æ—§æ–‡ä»¶: {filename}')

@timer
def test_baidu_api():
    """æµ‹è¯•ç™¾åº¦APIæ¥å£æ˜¯å¦æ­£å¸¸å·¥ä½œ"""
    test_ips = ['8.8.8.8', '1.1.1.1', '162.159.58.65']
    logging.info("æµ‹è¯•ç™¾åº¦APIæ¥å£...")
    success_count = 0
    
    for ip in test_ips:
        location, success = get_location_from_baidu(ip)
        status = "âœ…" if success else "âŒ"
        logging.info(f"{status} æµ‹è¯• {ip} -> {location}")
        if success:
            success_count += 1
        time.sleep(0.5)  # çŸ­æš‚å»¶è¿Ÿé¿å…è§¦å‘é™åˆ¶
    
    return success_count >= 2  # è‡³å°‘2ä¸ªæˆåŠŸç®—APIæ­£å¸¸

def generate_summary(ipv4_count, ipv6_count, non_us_ipv4_count, non_us_ipv6_count):
    """ç”Ÿæˆæ‰§è¡Œæ‘˜è¦"""
    summary = f"""
ğŸ“Š IPåœ°å€æ”¶é›†å®Œæˆæ‘˜è¦
========================
ğŸŒ æ•°æ®æº: {len(CONFIG['urls'])} ä¸ª
ğŸ“… æ‰§è¡Œæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

ğŸ“ æ”¶é›†ç»“æœ:
â”œâ”€â”€ IPv4åœ°å€: {ipv4_count} ä¸ª
â”œâ”€â”€ IPv6åœ°å€: {ipv6_count} ä¸ª
â”œâ”€â”€ éç¾å›½IPv4: {non_us_ipv4_count} ä¸ª
â””â”€â”€ éç¾å›½IPv6: {non_us_ipv6_count} ä¸ª

ğŸ’¾ è¾“å‡ºæ–‡ä»¶:
â”œâ”€â”€ ip.txt (æ‰€æœ‰IPv4åœ°å€)
â”œâ”€â”€ ipv6.txt (æ‰€æœ‰IPv6åœ°å€)
â””â”€â”€ {CONFIG['results_folder']}/non_us_ips_*.txt (éç¾å›½IPå†å²è®°å½•)

âœ… ä»»åŠ¡æ‰§è¡Œå®Œæˆ
"""
    print(summary)

@timer
def main():
    """ä¸»å‡½æ•°"""
    setup_logging()
    logging.info("ğŸš€ å¼€å§‹æ”¶é›†Cloudflare IPåœ°å€...")
    
    # APIæµ‹è¯•
    if not test_baidu_api():
        logging.warning("âš ï¸ ç™¾åº¦APIæµ‹è¯•ç»“æœä¸ç†æƒ³ï¼Œå¯èƒ½ä¼šå½±å“åœ°ç†ä½ç½®æŸ¥è¯¢")
    
    clean_old_files()
    
    # å¹¶è¡Œè·å–IPåœ°å€
    logging.info(f"ğŸŒ å¼€å§‹ä» {len(CONFIG['urls'])} ä¸ªæ•°æ®æºæ”¶é›†IPåœ°å€...")
    unique_ipv4, unique_ipv6 = process_urls_parallel(CONFIG['urls'])
    
    logging.info(f"âœ… æ”¶é›†å®Œæˆ: IPv4: {len(unique_ipv4)}ä¸ª, IPv6: {len(unique_ipv6)}ä¸ª")
    
    # å¹¶è¡ŒæŸ¥è¯¢åœ°ç†ä½ç½®å¹¶ä¿å­˜ç»“æœ
    non_us_ipv4 = []
    non_us_ipv6 = []
    
    if unique_ipv4:
        logging.info(f"ğŸ” å¼€å§‹å¤„ç†IPv4åœ°å€...")
        ipv4_results = query_ips_parallel(unique_ipv4, is_ipv6=False)
        non_us_ipv4, us_ipv4 = save_results_with_location(ipv4_results, 'ip.txt', False)
    
    if unique_ipv6:
        logging.info(f"ğŸ” å¼€å§‹å¤„ç†IPv6åœ°å€...")
        ipv6_results = query_ips_parallel(unique_ipv6, max_workers=8, is_ipv6=True)
        non_us_ipv6, us_ipv6 = save_results_with_location(ipv6_results, 'ipv6.txt', True)
    
    # ä¿å­˜éç¾å›½IPåˆ°æ—¥æœŸæ—¶é—´å‘½åçš„æ–‡ä»¶
    save_non_us_ips(non_us_ipv4, non_us_ipv6)
    
    # ç”Ÿæˆæ‘˜è¦
    generate_summary(
        len(unique_ipv4), 
        len(unique_ipv6),
        len(non_us_ipv4),
        len(non_us_ipv6)
    )
    
    logging.info("ğŸ‰ æ‰€æœ‰ä»»åŠ¡å®Œæˆï¼")

if __name__ == "__main__":
    main()
